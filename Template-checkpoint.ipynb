{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74655490-8a0f-4c9f-b2b3-82150dd02064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on 15-10-2024\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import cwt, find_peaks_cwt, ricker\n",
    "from scipy.signal import butter, lfilter, savgol_filter, hilbert\n",
    "\n",
    "from IntelliMaint.data_analysis import SOM\n",
    "from IntelliMaint.rul_models import GPRDegradationModel\n",
    "from IntelliMaint.eda import ExploratoryAnalysis\n",
    "from IntelliMaint.health_assessment import HealthIndicator\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, r'C:\\Users\\DELL\\Desktop\\Template\\IntelliMaint')\n",
    "\n",
    "from data_acquistion import DataAcquisition\n",
    "from feature_engineering import TimeDomain, FrequencyDomain\n",
    "from anomaly_detection import AnomalyDetection\n",
    "from bearing import Bearing\n",
    "from diagnostics import Diagnostic\n",
    "\n",
    "\n",
    "\n",
    "#########################3Data Acquisition##############################################\n",
    "# Get data from the directory\n",
    "data_dir_path = r'C:\\Users\\DELL\\Desktop\\Template\\data\\2nd_test\\2nd_test/'\n",
    "data_acquisition = DataAcquisition()\n",
    "\n",
    "# Get list of files\n",
    "files = DataAcquisition.get_file_list(data_dir_path)\n",
    "print(f\"Total files found: {len(files)}\")\n",
    "##################################################################################\n",
    "ber = 0\n",
    "n_cols = 4\n",
    "\n",
    "#############Feature Extraction #####################################################\n",
    "# Lists to store all features and timestamps\n",
    "all_features = []\n",
    "\n",
    "for file_path in files:\n",
    "    df = DataAcquisition.get_data_from_file(file_path)\n",
    "    bearing = Bearing(files)\n",
    "    signal = pd.to_numeric(df[str(ber)], errors='coerce').dropna().values\n",
    "     \n",
    "    # Extract features from the raw signal\n",
    "    features = bearing.extract_features(signal)\n",
    "    all_features.append(features)\n",
    "\n",
    "# Convert the list of all features into a NumPy array\n",
    "all_features = np.vstack(all_features)\n",
    "\n",
    "# Convert all_features to a DataFrame for easier viewing with column name\n",
    "feature_df = pd.DataFrame(all_features, columns=['kurtosis', 'skewness', 'ftf', 'bpfi', 'bpfo', 'bsf'])\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(\"First few rows of all_features:\")\n",
    "print(feature_df.head())\n",
    "#########################################################################################\n",
    "\n",
    "# Construct Health Indicator with SOM\n",
    "normal_data_pts_som = 200\n",
    "train_som = feature_df[:normal_data_pts_som]\n",
    "test_som = feature_df\n",
    "data_analysis = SOM()\n",
    "som, scaler_ = data_analysis.train(train_som)\n",
    "mqe = data_analysis.predict(som, test_som, scaler_).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(mqe)\n",
    "\n",
    "# Train Anomaly detection with normal health indicator\n",
    "normal_data_pts_cosmo = 200\n",
    "hi = mqe\n",
    "\n",
    "hi_train = hi[normal_data_pts_som:normal_data_pts_som+normal_data_pts_cosmo]\n",
    "hi_test = hi[normal_data_pts_som:]\n",
    "anomaly_detection = AnomalyDetection()\n",
    "hi_train = pd.DataFrame(hi_train)\n",
    "anomaly_detection.train_cosmo(hi_train)\n",
    "\n",
    "# Evaluate health score using health indicator test\n",
    "hi_test = pd.DataFrame(hi_test)\n",
    "health_score_test, _ = anomaly_detection.test_cosmo(hi_test)\n",
    "health_score_test = health_score_test.squeeze()\n",
    "\n",
    "hi_train = pd.DataFrame(hi_train)\n",
    "health_score_train, _ = anomaly_detection.test_cosmo(hi_train)\n",
    "health_score_train = health_score_train.squeeze()\n",
    "\n",
    "score_train = []\n",
    "score_test = []\n",
    "\n",
    "for i in range(hi_train.shape[0]):\n",
    "    score_train.append(health_score_train[i])\n",
    "\n",
    "for i in range(hi_test.shape[0]):\n",
    "    score_test.append(health_score_test[i])\n",
    "\n",
    "h_score = score_train + score_test\n",
    "h_score = np.array(h_score)\n",
    "\n",
    "window_length_filter = 50\n",
    "h_score_filtered = savgol_filter(h_score, window_length_filter, 1)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot([i for i in range(100, h_score.shape[0])], h_score[100:h_score.shape[0]], label='hi')\n",
    "plt.plot([i for i in range(100, h_score.shape[0])], h_score_filtered[100:h_score.shape[0]], label='hi_filtered')\n",
    "plt.ylabel('health score')\n",
    "plt.xlabel('samples')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "########################### Perform anomaly detection ##################################\n",
    "incipient_fault_threshold = 0.6\n",
    "normal_data_pts_som = 200\n",
    "deg_start_idx, score_till_incipient, initial_deg_pts = anomaly_detection.detect_anomaly(incipient_fault_threshold, normal_data_pts_som, files, ber, n_cols, som, scaler_, data_analysis, anomaly_detection)\n",
    "\n",
    "min_continuous_deg_pts = 10\n",
    "score_till_incipient_filtered = savgol_filter(score_till_incipient, 51, 1)\n",
    "initial_deg_pts_filtered = savgol_filter(initial_deg_pts, 3, 1)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(score_till_incipient, label='data below threshold')\n",
    "plt.plot(score_till_incipient_filtered, label='data below threshold filtered')\n",
    "plt.plot([i for i in range(len(score_till_incipient) - min_continuous_deg_pts, len(score_till_incipient))], initial_deg_pts, label='data above threshold')\n",
    "plt.plot([i for i in range(len(score_till_incipient) - min_continuous_deg_pts, len(score_till_incipient))], initial_deg_pts_filtered, label='data above threshold filtered')\n",
    "plt.plot([incipient_fault_threshold for i in range(len(score_till_incipient))], linestyle='dashed', color='#ffff00')\n",
    "plt.text(0, 0.55, \"incipient fault threshold\")\n",
    "plt.ylabel('health_score')\n",
    "plt.xlabel('samples')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "######################### Diagnostics ################################3\n",
    "#Prepare Data for Diagnostics\n",
    "df = bearing.prepare_data1(feature_df, deg_start_idx, normal_data_pts_som, 'outer_race')\n",
    "df.to_csv('2nd_test_bearing_1_outer_race1.csv', index=False)\n",
    "\n",
    "df_features, labels = bearing.prepare_data2(feature_df, deg_start_idx, normal_data_pts_som, 'outer_race')\n",
    "print(df_features.head(5))\n",
    "print(labels.head(5))\n",
    "\n",
    "# Evaluate Features for Diagnostics\n",
    "diagnostics = Diagnostic()\n",
    "labels = df['fault_modes']\n",
    "diagnostic_features = diagnostics.evaluate_diagnostic_features(df_features, labels)\n",
    "print(\"Diagnostic Features (sorted by FDR):\")\n",
    "for feature, fdr in diagnostic_features:\n",
    "    print(f\"{feature}: FDR = {fdr:.4f}\")\n",
    "diagnostics.plot_diagnostic_features(diagnostic_features, top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
